---
# This workflow uses actions that are not certified by GitHub. They are provided
# by a third-party and are governed by separate terms of service, privacy
# policy, and support documentation.

name: "ðŸŽ¯ Step: Upload to S3"
on:
  workflow_call:
    inputs:
      package-name:
        required: true
        type: string
      package-version:
        required: true
        type: string

defaults:
  run:
    shell: bash

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-upload
  cancel-in-progress: true

# Variables available to all jobs defined in this file
env:
  DOCKER_BUILDKIT: 1
  REGISTRY: ${{ vars.REGISTRY }}

# Declare default permissions as read only.
permissions: read-all

jobs:
  generate:
    runs-on: ubuntu-latest
    name: ðŸŽ¯ Upload to S3
    strategy:
      fail-fast: false

    container:
      image: ghcr.io/northwood-labs/package-builder/ubuntu-v22.04:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: --privileged

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@ec9f2d5744a09debf3a187a3f4f675c53b671911 # v2.13.0
        with:
          egress-policy: audit

      - name: Restore the cached packages from the previous stage
        uses: actions/cache/restore@0057852bfaa89a56745cba8c7296529d2fc39830 # v4.3.0
        id: cache
        with:
          key: "${{ inputs.package-name }}-${{ inputs.package-version }}"
          path: packages/${{ inputs.package-name }}/dist

      - name: Perform upload to S3
        working-directory: ./packages/${{ inputs.package-name }}/dist
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_DEFAULT_REGION: ${{ vars.AWS_DEFAULT_REGION }}
          AWS_REGION: ${{ vars.AWS_REGION }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWSSSEKMSID: "${{ secrets.AWSSSEKMSID }}"
          PACKAGE_BUCKET: ${{ vars.PACKAGE_BUCKET }}
        run: |
          if [[ -f $(find . -maxdepth 1 -type f -name "${{ inputs.package-name }}_*_arm64.deb") ]]; then
            aws s3 cp ${{ inputs.package-name }}_*_arm64.deb s3://${PACKAGE_BUCKET}/apt/pool/main/
          fi
          if [[ -f $(find . -maxdepth 1 -type f -name "${{ inputs.package-name }}_*_amd64.deb") ]]; then
            aws s3 cp ${{ inputs.package-name }}_*_amd64.deb s3://${PACKAGE_BUCKET}/apt/pool/main/
          fi
          if [[ -f $(find . -maxdepth 1 -type f -name "${{ inputs.package-name }}_*_all.deb") ]]; then
            aws s3 cp ${{ inputs.package-name }}_*_all.deb s3://${PACKAGE_BUCKET}/apt/pool/main/
          fi

          ARCH=("x86_64" "aarch64")

          # rpm
          AMZN=("2" "2023")
          for AL in "${AMZN[@]}"; do
            for CPU in "${ARCH[@]}"; do
              if [[ -f $(find . -maxdepth 1 -type f -name "${{ inputs.package-name }}-*.${CPU}.rpm") ]]; then
                aws s3 cp ${{ inputs.package-name }}-*.${CPU}.rpm s3://${PACKAGE_BUCKET}/rpm/amazonlinux/${AL}/${CPU}/
              fi
            done
          done

          # rpm noarch
          if [[ -f $(find . -maxdepth 1 -type f -name "${{ inputs.package-name }}-*.noarch.rpm") ]]; then
            aws s3 cp ${{ inputs.package-name }}-*.noarch.rpm s3://${PACKAGE_BUCKET}/rpm/amazonlinux/${AL}/noarch/
          fi

          # apk
          ALPINE=("3.17" "3.18" "3.19")
          for ALP in "${ALPINE[@]}"; do
            for CPU in "${ARCH[@]}"; do
              if [[ -f $(find . -maxdepth 1 -type f -name "${{ inputs.package-name }}*_${CPU}.apk") ]]; then
                aws s3 cp ${{ inputs.package-name }}*_${CPU}.apk s3://${PACKAGE_BUCKET}/apk/v${ALP}/main/${CPU}/
              fi
            done
          done

          # apk noarch
          if [[ -f $(find . -maxdepth 1 -type f -name "${{ inputs.package-name }}*_all.apk") ]]; then
            aws s3 cp ${{ inputs.package-name }}*_all.apk s3://${PACKAGE_BUCKET}/apk/v${ALP}/main/all/
          fi
